data: {"type": "plan", "plan": {"summary": "Generate LTX-2 text-to-video clip of sunset over ocean using ComfyUI gpu0_8188", "steps": [{"step": "List models and download ltx-2-19b-dev-fp8.safetensors and gemma_3_12B_it_fp4_mixed.safetensors if missing", "tool_category": "comfyui"}, {"step": "Discover LTX nodes with comfyui_describe_nodes(search='LTX', instance_id='gpu0_8188')", "tool_category": "comfyui"}, {"step": "Build API-format workflow for 2-3s LTX-2 T2V sunset over ocean using comfyui_build_workflow", "tool_category": "comfyui"}, {"step": "Queue and execute workflow to generate video clip", "tool_category": "comfyui"}], "needs_tools": true, "complexity": "moderate", "selected_categories": ["system", "workflow", "model", "comfyui"]}}

data: {"type": "conv_id", "conversation_id": "conv-9f509f1e", "persona_id": "system_agent", "autonomous": true}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}\n"}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}\n"}

data: {"type": "token", "text": "```"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 2.9}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 1, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 1}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": "_it"}

data: {"type": "token", "text": "_fp"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": "_m"}

data: {"type": "token", "text": "ixed"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "text"}

data: {"type": "token", "text": "_enc"}

data: {"type": "token", "text": "oders"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 2.9}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 3.9}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 5.8}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 2, "arguments": {"query": "gemma_3_12B_it_fp4_mixed", "category": "text_encoders"}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [], "huggingface_count": 0, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 2}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 3, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 3}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_templates"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "video"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_list_templates", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_list_templates", "tool_number": 4, "arguments": {"search": "LTX", "category": "video"}, "result": {"success": true, "templates": [{"name": "ltxv_image_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "ltxv_text_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_canny_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_canny_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_depth_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_depth_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_lora", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_lora.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_pose_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_pose_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}], "count": 10, "hint": "Built-in templates can be executed with comfyui_build_workflow(template_id=...) + comfyui_execute_workflow(). Native templates (video/image/etc) are graph-format workflows. To run them, use comfyui_describe_nodes(search='ltx') to learn the node inputs, then comfyui_build_workflow(nodes=[...]) to construct an API-format workflow."}}

data: {"type": "continuing", "tool_calls_so_far": 4}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "ltx"}

data: {"type": "token", "text": "-"}

data: {"type": "token", "text": "2"}

data: {"type": "token", "text": "-"}

data: {"type": "token", "text": "19"}

data: {"type": "token", "text": "b"}

data: {"type": "token", "text": "-dev"}

data: {"type": "token", "text": "-f"}

data: {"type": "token", "text": "p"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "check"}

data: {"type": "token", "text": "points"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 2.9}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 4.6}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 5, "arguments": {"query": "ltx-2-19b-dev-fp8", "category": "checkpoints"}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [{"name": "ltx-2-19b-dev-fp8_e5m2", "repo": "progmars/ltx-2-19b-dev-fp8_e5m2", "filename": "ltx-2-19b-dev-fp8_e5m2.safetensors", "folder": "checkpoints", "downloads": 0, "files": ["ltx-2-19b-dev-fp8_e5m2.safetensors", "ltx-2-19b-distilled-fp8_e5m2.safetensors"]}], "huggingface_count": 1, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 5}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": "_it"}

data: {"type": "token", "text": "_fp"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": "_m"}

data: {"type": "token", "text": "ixed"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "clip"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 2.8}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 4.4}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 6, "arguments": {"query": "gemma_3_12B_it_fp4_mixed", "category": "clip"}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [], "huggingface_count": 0, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 6}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_status"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_status", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_status", "elapsed": 3.4}

data: {"type": "tool_executing", "tool": "comfyui_status", "elapsed": 4.9}

data: {"type": "tool_call", "tool": "comfyui_status", "tool_number": 7, "arguments": {}, "result": {"success": true, "module_downloaded": true, "bootstrapped": true, "comfyui_installed": true, "api_running": true, "api_port": 5000, "instances": [{"instance_id": "gpu0_8188", "gpu_device": "0", "gpu_label": "GPU 0", "port": 8188, "host": "127.0.0.1", "vram_mode": "normal", "extra_args": [], "status": "running", "is_running": true, "url": "http://127.0.0.1:8188"}], "gpus": [{"index": 0, "name": "NVIDIA GeForce RTX 3060", "memory_total_mb": 12288}, {"index": 1, "name": "NVIDIA GeForce RTX 3090", "memory_total_mb": 24576}], "summary": "ComfyUI is installed. API running on port 5000. 1/1 instances running. GPUs: GPU ?: NVIDIA GeForce RTX 3060 (? free), GPU ?: NVIDIA GeForce RTX 3090 (? free)"}}

data: {"type": "continuing", "tool_calls_so_far": 7}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 2.9}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 8, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 8}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 9, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 9}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_templates"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "all"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_list_templates", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_list_templates", "tool_number": 10, "arguments": {"search": "LTX", "category": "all"}, "result": {"success": true, "templates": [{"name": "ltxv_image_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "ltxv_text_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_canny_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_canny_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_depth_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_depth_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_lora", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_lora.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_pose_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_pose_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "api_ltxv_image_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_api"}, {"name": "api_ltxv_text_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_api"}], "count": 12, "hint": "Built-in templates can be executed with comfyui_build_workflow(template_id=...) + comfyui_execute_workflow(). Native templates (video/image/etc) are graph-format workflows. To run them, use comfyui_describe_nodes(search='ltx') to learn the node inputs, then comfyui_build_workflow(nodes=[...]) to construct an API-format workflow."}}

data: {"type": "continuing", "tool_calls_so_far": 10}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_build"}

data: {"type": "token", "text": "_workflow"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "template"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "lt"}

data: {"type": "token", "text": "xv"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_build_workflow", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_build_workflow", "tool_number": 11, "arguments": {"template_id": "ltxv_text_to_video"}, "result": {"success": false, "error": "Unknown template: ltxv_text_to_video. Available: ['txt2img', 'img2img', 'upscale', 'inpaint', 'txt2img_hires', 'controlnet_pose']"}}

data: {"type": "continuing", "tool_calls_so_far": 11}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": "_it"}

data: {"type": "token", "text": "_fp"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": "_m"}

data: {"type": "token", "text": "ixed"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \"\""}

data: {"type": "token", "text": "}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 2.9}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 4.6}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 12, "arguments": {"query": "gemma_3_12B_it_fp4_mixed", "category": ""}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [], "huggingface_count": 0, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 12}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 13, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 13}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}\n"}

data: {"type": "token", "text": "```"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 2.9}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 14, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 14}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_templates"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "ltx"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "all"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_list_templates", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_list_templates", "tool_number": 15, "arguments": {"search": "ltx", "category": "all"}, "result": {"success": true, "templates": [{"name": "ltxv_image_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "ltxv_text_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_canny_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_canny_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_depth_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_depth_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_lora", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_lora.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_pose_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_pose_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "api_ltxv_image_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_api"}, {"name": "api_ltxv_text_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_api"}], "count": 12, "hint": "Built-in templates can be executed with comfyui_build_workflow(template_id=...) + comfyui_execute_workflow(). Native templates (video/image/etc) are graph-format workflows. To run them, use comfyui_describe_nodes(search='ltx') to learn the node inputs, then comfyui_build_workflow(nodes=[...]) to construct an API-format workflow."}}

data: {"type": "continuing", "tool_calls_so_far": 15}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_build"}

data: {"type": "token", "text": "_workflow"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "template"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "lt"}

data: {"type": "token", "text": "xv"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "overrides"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "prompt"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "A"}

data: {"type": "token", "text": " beautiful"}

data: {"type": "token", "text": " sunset"}

data: {"type": "token", "text": " over"}

data: {"type": "token", "text": " the"}

data: {"type": "token", "text": " ocean"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " the"}

data: {"type": "token", "text": " sun"}

data: {"type": "token", "text": " dipping"}

data: {"type": "token", "text": " below"}

data: {"type": "token", "text": " the"}

data: {"type": "token", "text": " horizon"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " vibrant"}

data: {"type": "token", "text": " orange"}

data: {"type": "token", "text": " and"}

data: {"type": "token", "text": " purple"}

data: {"type": "token", "text": " skies"}

data: {"type": "token", "text": " reflecting"}

data: {"type": "token", "text": " on"}

data: {"type": "token", "text": " gentle"}

data: {"type": "token", "text": " waves"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " cinematic"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " high"}

data: {"type": "token", "text": " quality"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " serene"}

data: {"type": "token", "text": " atmosphere"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "negative"}

data: {"type": "token", "text": "_prompt"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "bl"}

data: {"type": "token", "text": "urry"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " low"}

data: {"type": "token", "text": " quality"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " distorted"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " ugly"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " deformed"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "width"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "102"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "height"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "576"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "length"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "65"}

data: {"type": "token", "text": "}}}"}

data: {"type": "tool_executing", "tool": "comfyui_build_workflow", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_build_workflow", "tool_number": 16, "arguments": {"template_id": "ltxv_text_to_video", "overrides": {"prompt": "A beautiful sunset over the ocean, the sun dipping below the horizon, vibrant orange and purple skies reflecting on gentle waves, cinematic, high quality, serene atmosphere", "negative_prompt": "blurry, low quality, distorted, ugly, deformed", "width": 1024, "height": 576, "length": 65}}, "result": {"success": false, "error": "Unknown template: ltxv_text_to_video. Available: ['txt2img', 'img2img', 'upscale', 'inpaint', 'txt2img_hires', 'controlnet_pose']"}}

data: {"type": "continuing", "tool_calls_so_far": 16}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 2.8}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 17, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 17}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}\n"}

data: {"type": "token", "text": "```"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 3.0}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 18, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 18}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": " OR"}

data: {"type": "token", "text": " gem"}

data: {"type": "token", "text": "ma"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": " LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": " OR"}

data: {"type": "token", "text": " ltx"}

data: {"type": "token", "text": "av"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "check"}

data: {"type": "token", "text": "points"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 3.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 4.8}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 19, "arguments": {"query": "gemma_3_12B OR gemma 3 12B LTX OR ltxav", "category": "checkpoints"}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [], "huggingface_count": 0, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 19}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_templates"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "all"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_list_templates", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_list_templates", "tool_number": 20, "arguments": {"search": "LTX", "category": "all"}, "result": {"success": true, "templates": [{"name": "ltxv_image_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "ltxv_text_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_canny_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_canny_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_depth_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_depth_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_lora", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_lora.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_pose_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_pose_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "api_ltxv_image_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_api"}, {"name": "api_ltxv_text_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_api"}], "count": 12, "hint": "Built-in templates can be executed with comfyui_build_workflow(template_id=...) + comfyui_execute_workflow(). Native templates (video/image/etc) are graph-format workflows. To run them, use comfyui_describe_nodes(search='ltx') to learn the node inputs, then comfyui_build_workflow(nodes=[...]) to construct an API-format workflow."}}

data: {"type": "continuing", "tool_calls_so_far": 20}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 21, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 21}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 3.0}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 22, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 22}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_build"}

data: {"type": "token", "text": "_workflow"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "template"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "lt"}

data: {"type": "token", "text": "xv"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "overrides"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "prompt"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "A"}

data: {"type": "token", "text": " beautiful"}

data: {"type": "token", "text": " sunset"}

data: {"type": "token", "text": " over"}

data: {"type": "token", "text": " the"}

data: {"type": "token", "text": " ocean"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " serene"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " cinematic"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " vibrant"}

data: {"type": "token", "text": " colors"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " high"}

data: {"type": "token", "text": " quality"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " detailed"}

data: {"type": "token", "text": " waves"}

data: {"type": "token", "text": " and"}

data: {"type": "token", "text": " sky"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "negative"}

data: {"type": "token", "text": "_prompt"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "bl"}

data: {"type": "token", "text": "urry"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " low"}

data: {"type": "token", "text": " quality"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " artifacts"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " distorted"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "model"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "ltx"}

data: {"type": "token", "text": "-"}

data: {"type": "token", "text": "2"}

data: {"type": "token", "text": "-"}

data: {"type": "token", "text": "19"}

data: {"type": "token", "text": "b"}

data: {"type": "token", "text": "-dev"}

data: {"type": "token", "text": "-f"}

data: {"type": "token", "text": "p"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": ".s"}

data: {"type": "token", "text": "afet"}

data: {"type": "token", "text": "ensors"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "seed"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "42"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "steps"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "25"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "cfg"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": "."}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "width"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "102"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "height"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "576"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "length"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "75"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "frame"}

data: {"type": "token", "text": "_rate"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "25"}

data: {"type": "token", "text": "}}}"}

data: {"type": "tool_executing", "tool": "comfyui_build_workflow", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_build_workflow", "tool_number": 23, "arguments": {"template_id": "ltxv_text_to_video", "overrides": {"prompt": "A beautiful sunset over the ocean, serene, cinematic, vibrant colors, high quality, detailed waves and sky", "negative_prompt": "blurry, low quality, artifacts, distorted", "model": "ltx-2-19b-dev-fp8.safetensors", "seed": 42, "steps": 25, "cfg": 4.0, "width": 1024, "height": 576, "length": 75, "frame_rate": 25}}, "result": {"success": false, "error": "Unknown template: ltxv_text_to_video. Available: ['txt2img', 'img2img', 'upscale', 'inpaint', 'txt2img_hires', 'controlnet_pose']"}}

data: {"type": "continuing", "tool_calls_so_far": 23}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_templates"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "video"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_list_templates", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_list_templates", "tool_number": 24, "arguments": {"search": "LTX", "category": "video"}, "result": {"success": true, "templates": [{"name": "ltxv_image_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "ltxv_text_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_canny_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_canny_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_depth_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_depth_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_lora", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_lora.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_pose_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_pose_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}], "count": 10, "hint": "Built-in templates can be executed with comfyui_build_workflow(template_id=...) + comfyui_execute_workflow(). Native templates (video/image/etc) are graph-format workflows. To run them, use comfyui_describe_nodes(search='ltx') to learn the node inputs, then comfyui_build_workflow(nodes=[...]) to construct an API-format workflow."}}

data: {"type": "continuing", "tool_calls_so_far": 24}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_instances"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_instances", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_instances", "elapsed": 2.9}

data: {"type": "tool_call", "tool": "comfyui_list_instances", "tool_number": 25, "arguments": {}, "result": {"success": true, "instances": [{"instance_id": "gpu0_8188", "gpu_device": "0", "gpu_label": "GPU 0", "port": 8188, "host": "127.0.0.1", "vram_mode": "normal", "extra_args": [], "status": "running", "is_running": true, "url": "http://127.0.0.1:8188"}], "count": 1}}

data: {"type": "continuing", "tool_calls_so_far": 25}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 3.2}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 26, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 26}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 27, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 27}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_templates"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "all"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_list_templates", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_list_templates", "tool_number": 28, "arguments": {"search": "LTX", "category": "all"}, "result": {"success": true, "templates": [{"name": "ltxv_image_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "ltxv_text_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_canny_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_canny_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_depth_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_depth_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_lora", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_lora.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_pose_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_pose_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "api_ltxv_image_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_api"}, {"name": "api_ltxv_text_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_api"}], "count": 12, "hint": "Built-in templates can be executed with comfyui_build_workflow(template_id=...) + comfyui_execute_workflow(). Native templates (video/image/etc) are graph-format workflows. To run them, use comfyui_describe_nodes(search='ltx') to learn the node inputs, then comfyui_build_workflow(nodes=[...]) to construct an API-format workflow."}}

data: {"type": "continuing", "tool_calls_so_far": 28}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_build"}

data: {"type": "token", "text": "_workflow"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "template"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "lt"}

data: {"type": "token", "text": "xv"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_build_workflow", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_build_workflow", "tool_number": 29, "arguments": {"template_id": "ltxv_text_to_video", "instance_id": "gpu0_8188"}, "result": {"success": false, "error": "Invalid arguments for comfyui_build_workflow: ComfyUITools.comfyui_build_workflow() got an unexpected keyword argument 'instance_id'"}}

data: {"type": "continuing", "tool_calls_so_far": 29}

data: {"type": "token", "text": "```"}

data: {"type": "token", "text": "The"}

data: {"type": "token", "text": " LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": " nodes"}

data: {"type": "token", "text": " are"}

data: {"type": "token", "text": " available"}

data: {"type": "token", "text": " on"}

data: {"type": "token", "text": " gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": " instance"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " including"}

data: {"type": "token", "text": " specialized"}

data: {"type": "token", "text": " sam"}

data: {"type": "token", "text": "plers"}

data: {"type": "token", "text": " ("}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "XV"}

data: {"type": "token", "text": "Base"}

data: {"type": "token", "text": "Sampler"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " LT"}

data: {"type": "token", "text": "XV"}

data: {"type": "token", "text": "Loop"}

data: {"type": "token", "text": "ing"}

data: {"type": "token", "text": "Sampler"}

data: {"type": "token", "text": "),"}

data: {"type": "token", "text": " condition"}

data: {"type": "token", "text": "ers"}

data: {"type": "token", "text": " ("}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "XV"}

data: {"type": "token", "text": "Condition"}

data: {"type": "token", "text": "ing"}

data: {"type": "token", "text": "),"}

data: {"type": "token", "text": " mergers"}

data: {"type": "token", "text": " ("}

data: {"type": "token", "text": "Model"}

data: {"type": "token", "text": "Merge"}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "XV"}

data: {"type": "token", "text": "),"}

data: {"type": "token", "text": " and"}

data: {"type": "token", "text": " API"}

data: {"type": "token", "text": " nodes"}

data: {"type": "token", "text": " like"}

data: {"type": "token", "text": " L"}

data: {"type": "token", "text": "tx"}

data: {"type": "token", "text": "v"}

data: {"type": "token", "text": "Api"}

data: {"type": "token", "text": "Text"}

data: {"type": "token", "text": "To"}

data: {"type": "token", "text": "Video"}

data: {"type": "token", "text": " for"}

data: {"type": "token", "text": " easy"}

data: {"type": "token", "text": " T"}

data: {"type": "token", "text": "2"}

data: {"type": "token", "text": "V"}

data: {"type": "token", "text": ".\n\n"}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "XV"}

data: {"type": "token", "text": " templates"}

data: {"type": "token", "text": " exist"}

data: {"type": "token", "text": ":"}

data: {"type": "token", "text": " ltx"}

data: {"type": "token", "text": "v"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " ltx"}

data: {"type": "token", "text": "v"}

data: {"type": "token", "text": "_image"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " etc"}

data: {"type": "token", "text": ".\n\n"}

data: {"type": "token", "text": "Next"}

data: {"type": "token", "text": ":"}

data: {"type": "token", "text": " Build"}

data: {"type": "token", "text": " the"}

data: {"type": "token", "text": " ltx"}

data: {"type": "token", "text": "v"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": " template"}

data: {"type": "token", "text": " workflow"}

data: {"type": "token", "text": " ("}

data: {"type": "token", "text": "fix"}

data: {"type": "token", "text": "ing"}

data: {"type": "token", "text": " arg"}

data: {"type": "token", "text": " error"}

data: {"type": "token", "text": " by"}

data: {"type": "token", "text": " omitting"}

data: {"type": "token", "text": " instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": ")."}

data: {"type": "token", "text": "```\n\n"}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_build"}

data: {"type": "token", "text": "_workflow"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "template"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "lt"}

data: {"type": "token", "text": "xv"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_build_workflow", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_build_workflow", "tool_number": 30, "arguments": {"template_id": "ltxv_text_to_video"}, "result": {"success": false, "error": "Unknown template: ltxv_text_to_video. Available: ['txt2img', 'img2img', 'upscale', 'inpaint', 'txt2img_hires', 'controlnet_pose']"}}

data: {"type": "continuing", "tool_calls_so_far": 30}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 2.8}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 31, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 31}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": "_it"}

data: {"type": "token", "text": "_fp"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": "_m"}

data: {"type": "token", "text": "ixed"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "text"}

data: {"type": "token", "text": "_enc"}

data: {"type": "token", "text": "oders"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 2.8}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 4.5}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 32, "arguments": {"query": "gemma_3_12B_it_fp4_mixed", "category": "text_encoders"}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [], "huggingface_count": 0, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 32}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "XV"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 33, "arguments": {"search": "LTXV", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 33}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_templates"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "XV"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "all"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_list_templates", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_list_templates", "tool_number": 34, "arguments": {"search": "LTXV", "category": "all"}, "result": {"success": true, "templates": [{"name": "ltxv_image_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "ltxv_text_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "api_ltxv_image_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_api"}, {"name": "api_ltxv_text_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_api"}], "count": 4, "hint": "Built-in templates can be executed with comfyui_build_workflow(template_id=...) + comfyui_execute_workflow(). Native templates (video/image/etc) are graph-format workflows. To run them, use comfyui_describe_nodes(search='ltx') to learn the node inputs, then comfyui_build_workflow(nodes=[...]) to construct an API-format workflow."}}

data: {"type": "continuing", "tool_calls_so_far": 34}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 2.8}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 35, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 35}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": "_it"}

data: {"type": "token", "text": "_fp"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": "_m"}

data: {"type": "token", "text": "ixed"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "text"}

data: {"type": "token", "text": "_enc"}

data: {"type": "token", "text": "oders"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 2.8}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 4.3}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 36, "arguments": {"query": "gemma_3_12B_it_fp4_mixed", "category": "text_encoders"}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [], "huggingface_count": 0, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 36}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_instances"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_instances", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_instances", "elapsed": 2.8}

data: {"type": "tool_call", "tool": "comfyui_list_instances", "tool_number": 37, "arguments": {}, "result": {"success": true, "instances": [{"instance_id": "gpu0_8188", "gpu_device": "0", "gpu_label": "GPU 0", "port": 8188, "host": "127.0.0.1", "vram_mode": "normal", "extra_args": [], "status": "running", "is_running": true, "url": "http://127.0.0.1:8188"}], "count": 1}}

data: {"type": "continuing", "tool_calls_so_far": 37}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 38, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 38}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 2.8}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 39, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 39}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": "_it"}

data: {"type": "token", "text": "_fp"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": "_m"}

data: {"type": "token", "text": "ixed"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "text"}

data: {"type": "token", "text": "_enc"}

data: {"type": "token", "text": "oders"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 3.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 5.4}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 40, "arguments": {"query": "gemma_3_12B_it_fp4_mixed", "category": "text_encoders"}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [], "huggingface_count": 0, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 40}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_build"}

data: {"type": "token", "text": "_workflow"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "template"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "lt"}

data: {"type": "token", "text": "xv"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "overrides"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "prompt"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "A"}

data: {"type": "token", "text": " serene"}

data: {"type": "token", "text": " sunset"}

data: {"type": "token", "text": " over"}

data: {"type": "token", "text": " the"}

data: {"type": "token", "text": " calm"}

data: {"type": "token", "text": " ocean"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " orange"}

data: {"type": "token", "text": " skies"}

data: {"type": "token", "text": " reflecting"}

data: {"type": "token", "text": " on"}

data: {"type": "token", "text": " gentle"}

data: {"type": "token", "text": " waves"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " peaceful"}

data: {"type": "token", "text": " atmosphere"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " high"}

data: {"type": "token", "text": " quality"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " cinematic"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "model"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "ltx"}

data: {"type": "token", "text": "-"}

data: {"type": "token", "text": "2"}

data: {"type": "token", "text": "-"}

data: {"type": "token", "text": "19"}

data: {"type": "token", "text": "b"}

data: {"type": "token", "text": "-dev"}

data: {"type": "token", "text": "-f"}

data: {"type": "token", "text": "p"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": ".s"}

data: {"type": "token", "text": "afet"}

data: {"type": "token", "text": "ensors"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "duration"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "resolution"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "768"}

data: {"type": "token", "text": "x"}

data: {"type": "token", "text": "512"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "fps"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "25"}

data: {"type": "token", "text": ","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "steps"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " "}

data: {"type": "token", "text": "20"}

data: {"type": "token", "text": "}}}"}

data: {"type": "tool_executing", "tool": "comfyui_build_workflow", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_build_workflow", "tool_number": 41, "arguments": {"template_id": "ltxv_text_to_video", "overrides": {"prompt": "A serene sunset over the calm ocean, orange skies reflecting on gentle waves, peaceful atmosphere, high quality, cinematic", "model": "ltx-2-19b-dev-fp8.safetensors", "duration": 3, "resolution": "768x512", "fps": 25, "steps": 20}}, "result": {"success": false, "error": "Unknown template: ltxv_text_to_video. Available: ['txt2img', 'img2img', 'upscale', 'inpaint', 'txt2img_hires', 'controlnet_pose']"}}

data: {"type": "continuing", "tool_calls_so_far": 41}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_status"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_status", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_status", "elapsed": 2.4}

data: {"type": "tool_executing", "tool": "comfyui_status", "elapsed": 4.0}

data: {"type": "tool_executing", "tool": "comfyui_status", "elapsed": 5.7}

data: {"type": "tool_call", "tool": "comfyui_status", "tool_number": 42, "arguments": {}, "result": {"success": true, "module_downloaded": true, "bootstrapped": true, "comfyui_installed": true, "api_running": true, "api_port": 5000, "instances": [{"instance_id": "gpu0_8188", "gpu_device": "0", "gpu_label": "GPU 0", "port": 8188, "host": "127.0.0.1", "vram_mode": "normal", "extra_args": [], "status": "running", "is_running": true, "url": "http://127.0.0.1:8188"}], "gpus": [{"index": 0, "name": "NVIDIA GeForce RTX 3060", "memory_total_mb": 12288}, {"index": 1, "name": "NVIDIA GeForce RTX 3090", "memory_total_mb": 24576}], "summary": "ComfyUI is installed. API running on port 5000. 1/1 instances running. GPUs: GPU ?: NVIDIA GeForce RTX 3060 (? free), GPU ?: NVIDIA GeForce RTX 3090 (? free)"}}

data: {"type": "continuing", "tool_calls_so_far": 42}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 2.7}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 43, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 43}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\"}"}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_list_models", "elapsed": 2.9}

data: {"type": "tool_call", "tool": "comfyui_list_models", "tool_number": 44, "arguments": {}, "result": {"success": true, "models": {"checkpoints": [{"name": "ltx-2-19b-dev-fp8", "size_gb": 25.21901951916516, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\ltx-2-19b-dev-fp8.safetensors"}, {"name": "sd_xl_turbo_1.0_fp16", "size_gb": 6.461592302657664, "folder": "checkpoints", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\checkpoints\\sd_xl_turbo_1.0_fp16.safetensors"}], "diffusion_models": [], "vae": [{"name": "sdxl_vae", "size_gb": 0.31165886856615543, "folder": "vae", "path": "E:\\AgentNate\\modules\\comfyui\\comfyui\\models\\vae\\sdxl_vae.safetensors"}], "clip": [], "text_encoders": [], "loras": [], "controlnet": [], "gguf": [], "unet": [], "embeddings": [], "upscale_models": [], "clip_vision": [], "model_patches": [], "latent_upscale_models": []}, "count": 14}}

data: {"type": "continuing", "tool_calls_so_far": 44}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "3"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "12"}

data: {"type": "token", "text": "B"}

data: {"type": "token", "text": "_it"}

data: {"type": "token", "text": "_fp"}

data: {"type": "token", "text": "4"}

data: {"type": "token", "text": "_m"}

data: {"type": "token", "text": "ixed"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "text"}

data: {"type": "token", "text": "_enc"}

data: {"type": "token", "text": "oders"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 3.5}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 5.4}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 45, "arguments": {"query": "gemma_3_12B_it_fp4_mixed", "category": "text_encoders"}, "result": {"success": true, "registry_matches": [], "registry_match_count": 0, "huggingface_results": [], "huggingface_count": 0, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 45}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_list"}

data: {"type": "token", "text": "_templates"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_list_templates", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_list_templates", "tool_number": 46, "arguments": {"search": "LTX"}, "result": {"success": true, "templates": [{"name": "ltxv_image_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "ltxv_text_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_canny_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_canny_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_depth_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_depth_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_i2v_lora", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_i2v_lora.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_pose_to_video", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_pose_to_video.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "video_ltx2_t2v_distilled", "category": "video", "is_api": false, "has_preview": true, "file": "video_ltx2_t2v_distilled.json", "package": "comfyui_workflow_templates_media_video"}, {"name": "api_ltxv_image_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_image_to_video.json", "package": "comfyui_workflow_templates_media_api"}, {"name": "api_ltxv_text_to_video", "category": "api", "is_api": true, "has_preview": true, "file": "api_ltxv_text_to_video.json", "package": "comfyui_workflow_templates_media_api"}], "count": 12, "hint": "Built-in templates can be executed with comfyui_build_workflow(template_id=...) + comfyui_execute_workflow(). Native templates (video/image/etc) are graph-format workflows. To run them, use comfyui_describe_nodes(search='ltx') to learn the node inputs, then comfyui_build_workflow(nodes=[...]) to construct an API-format workflow."}}

data: {"type": "continuing", "tool_calls_so_far": 46}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_build"}

data: {"type": "token", "text": "_workflow"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "template"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "lt"}

data: {"type": "token", "text": "xv"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_to"}

data: {"type": "token", "text": "_video"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_build_workflow", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_build_workflow", "tool_number": 47, "arguments": {"template_id": "ltxv_text_to_video"}, "result": {"success": false, "error": "Unknown template: ltxv_text_to_video. Available: ['txt2img', 'img2img', 'upscale', 'inpaint', 'txt2img_hires', 'controlnet_pose']"}}

data: {"type": "continuing", "tool_calls_so_far": 47}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_desc"}

data: {"type": "token", "text": "ribe"}

data: {"type": "token", "text": "_nodes"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "search"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "LT"}

data: {"type": "token", "text": "X"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "instance"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "gpu"}

data: {"type": "token", "text": "0"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "818"}

data: {"type": "token", "text": "8"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "tool_executing", "tool": "comfyui_describe_nodes", "elapsed": 0.0}

data: {"type": "tool_call", "tool": "comfyui_describe_nodes", "tool_number": 48, "arguments": {"search": "LTX", "instance_id": "gpu0_8188"}, "result": {"success": true, "nodes": {"ModelMergeLTXV": {"category": "advanced/model_merging/model_specific", "description": "", "inputs": {"model1": {"type": "MODEL", "required": true}, "model2": {"type": "MODEL", "required": true}, "patchify_proj.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "adaln_single.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "caption_projection.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.0.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.1.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.2.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.3.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.4.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.5.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.6.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.7.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.8.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.9.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.10.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.11.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.12.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.13.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.14.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.15.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.16.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.17.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.18.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.19.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.20.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.21.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.22.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.23.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.24.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.25.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.26.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "transformer_blocks.27.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "scale_shift_table": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "proj_out.": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVLatentUpsampler": {"category": "latent/video", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "upscale_model": {"type": "LATENT_UPSCALE_MODEL", "required": true}, "vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAudioVAELoader": {"category": "audio", "description": "", "inputs": {"ckpt_name": {"type": "COMBO", "required": true}}, "outputs": ["VAE"], "output_names": ["Audio VAE"], "source": "live_instance"}, "LTXVAudioVAEEncode": {"category": "audio", "description": "", "inputs": {"audio": {"type": "AUDIO", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Audio Latent"], "source": "live_instance"}, "LTXVAudioVAEDecode": {"category": "audio", "description": "", "inputs": {"samples": {"type": "LATENT", "required": true}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["AUDIO"], "output_names": ["Audio"], "source": "live_instance"}, "LTXVEmptyLatentAudio": {"category": "latent/audio", "description": "", "inputs": {"frames_number": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 1000}, "frame_rate": {"type": "INT", "required": true, "default": 25, "min": 1, "max": 1000}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "audio_vae": {"type": "VAE", "required": true}}, "outputs": ["LATENT"], "output_names": ["Latent"], "source": "live_instance"}, "LTXAVTextEncoderLoader": {"category": "advanced/loaders", "description": "[Recipes]\n\nltxav: gemma 3 12B", "inputs": {"text_encoder": {"type": "COMBO", "required": true}, "ckpt_name": {"type": "COMBO", "required": true}, "device": {"type": "COMBO", "required": true}}, "outputs": ["CLIP"], "output_names": ["CLIP"], "source": "live_instance"}, "EmptyLTXVLatentVideo": {"category": "latent/video/ltxv", "description": "", "inputs": {"width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideo": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "length": {"type": "INT", "required": true, "default": 97, "min": 9, "max": 16384}, "batch_size": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 4096}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVImgToVideoInplace": {"category": "conditioning/video_models", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "ModelSamplingLTXV": {"category": "advanced/model", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVConditioning": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "frame_rate": {"type": "FLOAT", "required": true, "default": 25.0, "min": 0.0, "max": 1000.0}}, "outputs": ["CONDITIONING", "CONDITIONING"], "output_names": ["positive", "negative"], "source": "live_instance"}, "LTXVScheduler": {"category": "sampling/custom_sampling/schedulers", "description": "", "inputs": {"steps": {"type": "INT", "required": true, "default": 20, "min": 1, "max": 10000}, "max_shift": {"type": "FLOAT", "required": true, "default": 2.05, "min": 0.0, "max": 100.0}, "base_shift": {"type": "FLOAT", "required": true, "default": 0.95, "min": 0.0, "max": 100.0}, "stretch": {"type": "BOOLEAN", "required": true, "default": true}, "terminal": {"type": "FLOAT", "required": true, "default": 0.1, "min": 0.0, "max": 0.99}, "latent": {"type": "LATENT", "required": false}}, "outputs": ["SIGMAS"], "output_names": ["SIGMAS"], "source": "live_instance"}, "LTXVAddGuide": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVPreprocess": {"category": "image", "description": "", "inputs": {"image": {"type": "IMAGE", "required": true}, "img_compression": {"type": "INT", "required": true, "default": 35, "min": 0, "max": 100}}, "outputs": ["IMAGE"], "output_names": ["output_image"], "source": "live_instance"}, "LTXVCropGuides": {"category": "conditioning/video_models", "description": "", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVConcatAVLatent": {"category": "latent/video/ltxv", "description": "", "inputs": {"video_latent": {"type": "LATENT", "required": true}, "audio_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVSeparateAVLatent": {"category": "latent/video/ltxv", "description": "LTXV Separate AV Latent", "inputs": {"av_latent": {"type": "LATENT", "required": true}}, "outputs": ["LATENT", "LATENT"], "output_names": ["video_latent", "audio_latent"], "source": "live_instance"}, "LtxvApiTextToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution.", "inputs": {"model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "LtxvApiImageToVideo": {"category": "api node/video/LTXV", "description": "Professional-quality videos with customizable duration and resolution based on start image.", "inputs": {"image": {"type": "IMAGE", "required": true}, "model": {"type": "COMBO", "required": true}, "prompt": {"type": "STRING", "required": true, "default": ""}, "duration": {"type": "COMBO", "required": true, "default": 8}, "resolution": {"type": "COMBO", "required": true}, "fps": {"type": "COMBO", "required": true, "default": 25}, "generate_audio": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["VIDEO"], "output_names": ["VIDEO"], "source": "live_instance"}, "Set VAE Decoder Noise": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "timestep": {"type": "FLOAT", "required": true, "default": 0.05, "min": 0.0, "max": 1.0}, "scale": {"type": "FLOAT", "required": true, "default": 0.025, "min": 0.0, "max": 1.0}, "seed": {"type": "INT", "required": true, "default": 42, "min": 0, "max": 18446744073709551615}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVLinearOverlapLatentTransition": {"category": "Lightricks/latent", "description": "", "inputs": {"samples1": {"type": "LATENT", "required": true}, "samples2": {"type": "LATENT", "required": true}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 256}, "axis": {"type": "INT", "required": false, "default": 0}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVAddGuideAdvanced": {"category": "conditioning/video_models", "description": "Adds a conditioning frame or a video at a specific frame index. This node is used to add a keyframe or a video segment which should appear in the generated video at a specified index. It resizes the image to the correct size and applies preprocessing to it.", "inputs": {"positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "vae": {"type": "VAE", "required": true}, "latent": {"type": "LATENT", "required": true}, "image": {"type": "IMAGE", "required": true}, "frame_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "crf": {"type": "INT", "required": true, "default": 29, "min": 0, "max": 51}, "blur_radius": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 7}, "interpolation": {"type": "COMBO", "required": true, "options": ["lanczos", "bislerp", "nearest", "bilinear", "bicubic", "area", "nearest-exact"], "default": "lanczos"}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAddLatentGuide": {"category": "ltxtricks", "description": "Adds a keyframe or a video segment at a specific frame index.", "inputs": {"vae": {"type": "VAE", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "latent": {"type": "LATENT", "required": true}, "guiding_latent": {"type": "LATENT", "required": true}, "latent_idx": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["CONDITIONING", "CONDITIONING", "LATENT"], "output_names": ["positive", "negative", "latent"], "source": "live_instance"}, "LTXVAdainLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "reference": {"type": "LATENT", "required": true}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVImgToVideoConditionOnly": {"category": "conditioning/video_models", "description": "Applies image conditioning to the first frames of an existing latent. Creates a noise mask to control conditioning strength.", "inputs": {"vae": {"type": "VAE", "required": true}, "image": {"type": "IMAGE", "required": true}, "latent": {"type": "LATENT", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "bypass": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["LATENT"], "output_names": ["latent"], "source": "live_instance"}, "LTXVPerStepAdainPatcher": {"category": "Lightricks/latents", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "factors": {"type": "STRING", "required": true, "default": "0.9, 0.75, 0.0"}, "reference": {"type": "LATENT", "required": true}, "per_frame": {"type": "BOOLEAN", "required": false, "default": false}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVApplySTG": {"category": "lightricks/LTXV", "description": "Defines the blocks to apply the STG to.", "inputs": {"model": {"type": "MODEL", "required": true}, "block_indices": {"type": "STRING", "required": true, "default": "14, 19"}}, "outputs": ["MODEL"], "output_names": ["model"], "source": "live_instance"}, "LTXVBaseSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "width": {"type": "INT", "required": true, "default": 768, "min": 64, "max": 16384}, "height": {"type": "INT", "required": true, "default": 512, "min": 64, "max": 16384}, "num_frames": {"type": "INT", "required": true, "default": 97, "min": 1, "max": 16384}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "strength": {"type": "FLOAT", "required": false, "default": 0.9, "min": 0, "max": 1}, "crop": {"type": "COMBO", "required": false, "options": ["center", "disabled"], "default": "disabled"}, "crf": {"type": "INT", "required": false, "default": 35, "min": 0, "max": 100}, "blur": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 10}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised", "positive", "negative"], "source": "live_instance"}, "LTXVInContextSampler": {"category": "sampling", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "guiding_latents": {"type": "LATENT", "required": true}, "optional_cond_images": {"type": "IMAGE", "required": false}, "num_frames": {"type": "INT", "required": false, "default": -1, "min": -1, "max": 1000}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVExtendSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "num_new_frames": {"type": "INT", "required": true, "default": 80, "min": -1, "max": 16384}, "frame_overlap": {"type": "INT", "required": true, "default": 16, "min": 16, "max": 128}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "noise": {"type": "NOISE", "required": true}, "strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false}, "cond_image_strength": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["LATENT", "CONDITIONING", "CONDITIONING"], "output_names": ["denoised_video", "positive", "negative"], "source": "live_instance"}, "LTXVNormalizingSampler": {"category": "utility", "description": "", "inputs": {"noise": {"type": "NOISE", "required": true}, "guider": {"type": "GUIDER", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "latent_image": {"type": "LATENT", "required": true}, "video_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,1,1,1,1,1,1"}, "audio_normalization_factors": {"type": "STRING", "required": true, "default": "1,1,0.25,1,1,0.25,1,1"}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVPreprocessMasks": {"category": "Lightricks/mask_operations", "description": "Preprocess masks to be used for masking latents in the LTXVideo model.", "inputs": {"masks": {"type": "MASK", "required": true}, "vae": {"type": "VAE", "required": true}, "invert_input_masks": {"type": "BOOLEAN", "required": true, "default": false}, "ignore_first_mask": {"type": "BOOLEAN", "required": true, "default": true}, "pooling_method": {"type": "COMBO", "required": true, "options": ["max", "mean", "min"], "default": "max"}, "grow_mask": {"type": "INT", "required": true, "default": 0, "min": -16384, "max": 16384}, "tapered_corners": {"type": "BOOLEAN", "required": true, "default": true}, "clamp_min": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "clamp_max": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}}, "outputs": ["MASK"], "output_names": ["MASK"], "source": "live_instance"}, "LTXVPatcherVAE": {"category": "lightricks/LTXV", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}}, "outputs": ["VAE"], "output_names": ["VAE"], "source": "live_instance"}, "LTXVPromptEnhancer": {"category": "lightricks/LTXV", "description": "Enhances text prompts for image generation using LLMs. Optionally incorporates reference images to create more contextually relevant descriptions.", "inputs": {"prompt": {"type": "STRING", "required": true}, "prompt_enhancer": {"type": "LTXV_PROMPT_ENHANCER", "required": true}, "max_resulting_tokens": {"type": "INT", "required": true, "default": 256, "min": 32, "max": 512}, "image_prompt": {"type": "IMAGE", "required": false}}, "outputs": ["STRING"], "output_names": ["str"], "source": "live_instance"}, "LTXVPromptEnhancerLoader": {"category": "lightricks/LTXV", "description": "Downloads and initializes LLM and image captioning models from Hugging Face to enhance text prompts for image generation.", "inputs": {"llm_name": {"type": "STRING", "required": true, "default": ["unsloth/Llama-3.2-3B-Instruct"]}, "image_captioner_name": {"type": "STRING", "required": true, "default": ["MiaoshouAI/Florence-2-large-PromptGen-v2.0"]}}, "outputs": ["LTXV_PROMPT_ENHANCER"], "output_names": ["prompt_enhancer"], "source": "live_instance"}, "LTXQ8Patch": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "use_fp8_attention": {"type": "BOOLEAN", "required": true, "default": false}, "quantization_preset": {"type": "COMBO", "required": true, "options": ["0.9.8", "ltxv2", "full_bf16", "custom"], "default": "0.9.8"}, "quantize_self_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "quantize_ffn": {"type": "BOOLEAN", "required": true, "default": true}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVQ8LoraModelLoader": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "lora_name": {"type": "COMBO", "required": true, "options": [], "default": null}, "strength_model": {"type": "FLOAT", "required": true, "default": 1.0, "min": -100.0, "max": 100.0}}, "outputs": ["MODEL"], "output_names": ["MODEL"], "source": "live_instance"}, "LTXVSelectLatents": {"category": "latent/video", "description": "Selects a range of frames from the video latent. start_index and end_index define a closed interval (inclusive of both endpoints).", "inputs": {"samples": {"type": "LATENT", "required": true}, "start_index": {"type": "INT", "required": true, "default": 0, "min": -9999, "max": 9999}, "end_index": {"type": "INT", "required": true, "default": -1, "min": -9999, "max": 9999}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVSetVideoLatentNoiseMasks": {"category": "latent/video", "description": "Applies multiple masks to a video latent. masks can be 2D, 3D, or 4D tensors. If there are fewer masks than frames, the last mask will be reused.", "inputs": {"samples": {"type": "LATENT", "required": true}, "masks": {"type": "MASK", "required": true}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}, "LTXVTiledSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "latents_cond_strength": {"type": "FLOAT", "required": true, "default": 0.15, "min": 0.0, "max": 1.0}, "boost_latent_similarity": {"type": "BOOLEAN", "required": true, "default": false}, "crop": {"type": "COMBO", "required": true, "options": ["center", "disabled"], "default": "disabled"}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_cond_indices": {"type": "STRING", "required": false, "default": "0"}, "images_cond_strengths": {"type": "STRING", "required": false, "default": "0.9"}}, "outputs": ["LATENT", "LATENT"], "output_names": ["output", "denoised_output"], "source": "live_instance"}, "LTXVLoopingSampler": {"category": "sampling", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "vae": {"type": "VAE", "required": true}, "noise": {"type": "NOISE", "required": true}, "sampler": {"type": "SAMPLER", "required": true}, "sigmas": {"type": "SIGMAS", "required": true}, "guider": {"type": "GUIDER", "required": true}, "latents": {"type": "LATENT", "required": true}, "temporal_tile_size": {"type": "INT", "required": true, "default": 80, "min": 24, "max": 1000}, "temporal_overlap": {"type": "INT", "required": true, "default": 24, "min": 16, "max": 80}, "guiding_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "temporal_overlap_cond_strength": {"type": "FLOAT", "required": true, "default": 0.5, "min": 0.0, "max": 1.0}, "cond_image_strength": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 1.0}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "spatial_overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "optional_cond_images": {"type": "IMAGE", "required": false}, "optional_guiding_latents": {"type": "LATENT", "required": false}, "adain_factor": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 1.0}, "optional_positive_conditionings": {"type": "CONDITIONING", "required": false}, "optional_negative_index_latents": {"type": "LATENT", "required": false}, "guiding_start_step": {"type": "INT", "required": false, "default": 0, "min": 0, "max": 1000}, "guiding_end_step": {"type": "INT", "required": false, "default": 1000, "min": 0, "max": 1000}, "optional_cond_image_indices": {"type": "STRING", "required": false, "default": "0"}, "optional_normalizing_latents": {"type": "LATENT", "required": false}}, "outputs": ["LATENT"], "output_names": ["denoised_output"], "source": "live_instance"}, "LTXVTiledVAEDecode": {"category": "latent", "description": "", "inputs": {"vae": {"type": "VAE", "required": true}, "latents": {"type": "LATENT", "required": true}, "horizontal_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "vertical_tiles": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 6}, "overlap": {"type": "INT", "required": true, "default": 1, "min": 1, "max": 8}, "last_frame_fix": {"type": "BOOLEAN", "required": true, "default": false}, "working_device": {"type": "COMBO", "required": false, "options": ["cpu", "auto"], "default": "auto"}, "working_dtype": {"type": "COMBO", "required": false, "options": ["float16", "float32", "auto"], "default": "auto"}}, "outputs": ["IMAGE"], "output_names": ["image"], "source": "live_instance"}, "MultimodalGuider": {"category": "lightricks/LTXV", "description": "", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": true}, "skip_blocks": {"type": "STRING", "required": true, "default": ""}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "GuiderParameters": {"category": "lightricks/LTXV", "description": "", "inputs": {"modality": {"type": "COMBO", "required": true, "options": ["VIDEO", "AUDIO"], "default": "VIDEO"}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "perturb_attn": {"type": "BOOLEAN", "required": true, "default": true}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 100.0}, "modality_scale": {"type": "FLOAT", "required": true, "default": 0.0, "min": 0.0, "max": 100.0}, "skip_step": {"type": "INT", "required": true, "default": 0, "min": 0, "max": 100}, "cross_attn": {"type": "BOOLEAN", "required": true, "default": true}, "parameters": {"type": "GUIDER_PARAMETERS", "required": false, "default": null}}, "outputs": ["GUIDER_PARAMETERS"], "output_names": ["GUIDER_PARAMETERS"], "source": "live_instance"}, "STGAdvancedPresets": {"category": "lightricks/LTXV", "description": "", "inputs": {"preset": {"type": "COMBO", "required": true, "options": ["Custom", "13b Dynamic", "13b Balanced", "13b Upscale", "13b Distilled", "2b"], "default": "13b Balanced"}}, "outputs": ["STG_ADVANCED_PRESET"], "output_names": ["STG_ADVANCED_PRESET"], "source": "live_instance"}, "STGGuiderAdvanced": {"category": "lightricks/LTXV", "description": "\n    The Advanced STG Guider implements sophisticated techniques for controlling the denoising process:\n\n    It creates a dynamic mapping from scheduler-defined sigma values to CFG and STG (Spatio-Temporal Skip Guidance [1]) parameters.\n    This approach establishes distinct sigma value ranges that operate independently of step numbers, allowing precise control over:\n    \u2022 CFG scale\n    \u2022 STG scale and rescale factors\n    \u2022 STG attention layer skipping patterns\n\n    The guider also supports:\n    \u2022 CFG-Zero* [2] rescaling, which dynamically adjusts negative predictions based on the dot product between positive and negative signals\n    \u2022 Threshold-based noise prediction zeroing for steps with sigma values exceeding a specified threshold\n\n    For example if the sigma ranges are defined as [1.0, 0.9, 0.85, 0.6] and the CFG values are defined as [4, 3, 2, 1] and STG scale values\n    are defined as [2, 2, 2, 1] and STG rescale values are defined as [1, 1, 1, 1] and STG layers indices are defined as [[14, 17], [14, 16], [14], [14]], then the guider will:\n    - use CFG=4, STG scale=2, STG rescale=1 and STG layers indices = [14, 17] for sigma in the range (0.9, 1.0]\n    - use CFG=3, STG scale=2, STG rescale=1 and STG layers indices = [14, 16] for sigma in the range (0.85, 0.9]\n    - use CFG=2, STG scale=2, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.8, 0.85]\n    - use CFG=1, STG scale=1, STG rescale=1 and STG layers indices = [14] for sigma in the range (0.6, 0.8]\n\n    The guider will use the same parameters for the same sigma values, regardless of the step number.\n\n    References:\n    [1] https://arxiv.org/abs/2411.18664\n    [2] https://arxiv.org/abs/2503.18886\n\n    ", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "skip_steps_sigma_threshold": {"type": "FLOAT", "required": true, "default": 0.998, "min": 0.0, "max": 100.0}, "cfg_star_rescale": {"type": "BOOLEAN", "required": true, "default": true}, "sigmas": {"type": "STRING", "required": true, "default": "1.0, 0.9933, 0.9850, 0.9767, 0.9008, 0.6180"}, "cfg_values": {"type": "STRING", "required": true, "default": "8, 6, 6, 4, 3, 1"}, "stg_scale_values": {"type": "STRING", "required": true, "default": "4, 4, 3, 2, 1, 0"}, "stg_rescale_values": {"type": "STRING", "required": true, "default": "1, 1, 1, 1, 1, 1"}, "stg_layers_indices": {"type": "STRING", "required": true, "default": "[29], [29], [29], [29], [29], [29]"}, "preset": {"type": "STG_ADVANCED_PRESET", "required": false}, "apply_apg": {"type": "BOOLEAN", "required": false, "default": false}, "apg_cfg_scale": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "eta": {"type": "FLOAT", "required": false, "default": 1.0, "min": 0.0, "max": 100.0}, "norm_threshold": {"type": "FLOAT", "required": false, "default": 0.0, "min": 0.0, "max": 100.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "STGGuiderNode": {"category": "lightricks/LTXV", "description": "Implements Spatiotemporal Skip Guidance (STG), a training-free method enhancing transformer-based video diffusion models by selectively skipping layers during sampling. This approach improves video quality without sacrificing diversity or motion fidelity.Reference: https://arxiv.org/abs/2411.18664.", "inputs": {"model": {"type": "MODEL", "required": true}, "positive": {"type": "CONDITIONING", "required": true}, "negative": {"type": "CONDITIONING", "required": true}, "cfg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "stg": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.0, "max": 100.0}, "rescale": {"type": "FLOAT", "required": true, "default": 0.7, "min": 0.0, "max": 1.0}}, "outputs": ["GUIDER"], "output_names": ["GUIDER"], "source": "live_instance"}, "LTXVMultiPromptProvider": {"category": "prompt", "description": "", "inputs": {"prompts": {"type": "STRING", "required": true}, "clip": {"type": "CLIP", "required": true}}, "outputs": ["CONDITIONING"], "output_names": ["conditionings"], "source": "live_instance"}, "LTXVStatNormLatent": {"category": "Lightricks/latents", "description": "", "inputs": {"latents": {"type": "LATENT", "required": true}, "target_mean": {"type": "FLOAT", "required": true, "default": 0.0, "min": -10.0, "max": 10.0}, "target_std": {"type": "FLOAT", "required": true, "default": 1.0, "min": 0.01, "max": 10.0}, "percentile": {"type": "FLOAT", "required": true, "default": 95.0, "min": 50.0, "max": 100.0}, "factor": {"type": "FLOAT", "required": true, "default": 1.0, "min": -10.0, "max": 10.0}, "clip_outliers": {"type": "BOOLEAN", "required": true, "default": false}}, "outputs": ["LATENT"], "output_names": ["LATENT"], "source": "live_instance"}}, "count": 50, "source": "live_instance", "hint": "These nodes were found on the running instance (not in static catalog)."}}

data: {"type": "continuing", "tool_calls_so_far": 48}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_search"}

data: {"type": "token", "text": "_models"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "query"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "g"}

data: {"type": "token", "text": "emma"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "category"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \"\""}

data: {"type": "token", "text": "}}"}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 2.8}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 3.9}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 4.9}

data: {"type": "tool_executing", "tool": "comfyui_search_models", "elapsed": 6.8}

data: {"type": "tool_call", "tool": "comfyui_search_models", "tool_number": 49, "arguments": {"query": "gemma", "category": ""}, "result": {"success": true, "registry_matches": [{"id": "ltx2_text_encoder", "name": "LTX-2 Gemma 12B (FP4 Mixed)", "folder": "text_encoders", "size_gb": 6.0, "repo": "Comfy-Org/ltx-2", "filename": "split_files/text_encoders/gemma_3_12B_it_fp4_mixed.safetensors", "status": "missing"}], "registry_match_count": 1, "huggingface_results": [{"name": "gemma-3-27b-it", "repo": "google/gemma-3-27b-it", "filename": "model-00001-of-00012.safetensors", "folder": "checkpoints", "downloads": 1683744, "files": ["model-00001-of-00012.safetensors", "model-00002-of-00012.safetensors", "model-00003-of-00012.safetensors", "model-00004-of-00012.safetensors", "model-00005-of-00012.safetensors"]}, {"name": "gemma-3-1b-it", "repo": "google/gemma-3-1b-it", "filename": "model.safetensors", "folder": "checkpoints", "downloads": 1390709, "files": ["model.safetensors"]}, {"name": "gemma-3-12b-it", "repo": "google/gemma-3-12b-it", "filename": "model-00001-of-00005.safetensors", "folder": "checkpoints", "downloads": 1252051, "files": ["model-00001-of-00005.safetensors", "model-00002-of-00005.safetensors", "model-00003-of-00005.safetensors", "model-00004-of-00005.safetensors", "model-00005-of-00005.safetensors"]}, {"name": "gemma-3-4b-it", "repo": "google/gemma-3-4b-it", "filename": "model-00001-of-00002.safetensors", "folder": "checkpoints", "downloads": 1167148, "files": ["model-00001-of-00002.safetensors", "model-00002-of-00002.safetensors"]}, {"name": "gemma-2-27b-it", "repo": "google/gemma-2-27b-it", "filename": "model-00001-of-00012.safetensors", "folder": "checkpoints", "downloads": 380627, "files": ["model-00001-of-00012.safetensors", "model-00002-of-00012.safetensors", "model-00003-of-00012.safetensors", "model-00004-of-00012.safetensors", "model-00005-of-00012.safetensors"]}, {"name": "gemma-3-4b-it-qat-4bit", "repo": "mlx-community/gemma-3-4b-it-qat-4bit", "filename": "model.safetensors", "folder": "checkpoints", "downloads": 354346, "files": ["model.safetensors"]}, {"name": "gemma-2-2b-it", "repo": "google/gemma-2-2b-it", "filename": "model-00001-of-00002.safetensors", "folder": "checkpoints", "downloads": 325471, "files": ["model-00001-of-00002.safetensors", "model-00002-of-00002.safetensors"]}, {"name": "bge-multilingual-gemma2", "repo": "BAAI/bge-multilingual-gemma2", "filename": "model-00001-of-00004.safetensors", "folder": "checkpoints", "downloads": 302962, "files": ["model-00001-of-00004.safetensors", "model-00002-of-00004.safetensors", "model-00003-of-00004.safetensors", "model-00004-of-00004.safetensors"]}, {"name": "gemma-3n-E2B-it", "repo": "google/gemma-3n-E2B-it", "filename": "model-00001-of-00003.safetensors", "folder": "checkpoints", "downloads": 301753, "files": ["model-00001-of-00003.safetensors", "model-00002-of-00003.safetensors", "model-00003-of-00003.safetensors"]}, {"name": "gemma-7b-it", "repo": "google/gemma-7b-it", "filename": "model-00001-of-00004.safetensors", "folder": "checkpoints", "downloads": 233628, "files": ["model-00001-of-00004.safetensors", "model-00002-of-00004.safetensors", "model-00003-of-00004.safetensors", "model-00004-of-00004.safetensors"]}, {"name": "tiny-random-Gemma2ForCausalLM", "repo": "hmellor/tiny-random-Gemma2ForCausalLM", "filename": "model.safetensors", "folder": "checkpoints", "downloads": 214492, "files": ["model.safetensors"]}, {"name": "gemma-3-27b-it-AWQ-INT4", "repo": "pytorch/gemma-3-27b-it-AWQ-INT4", "filename": "pytorch_model-00001-of-00004.bin", "folder": "checkpoints", "downloads": 192911, "files": ["pytorch_model-00001-of-00004.bin", "pytorch_model-00002-of-00004.bin", "pytorch_model-00003-of-00004.bin", "pytorch_model-00004-of-00004.bin"]}, {"name": "gemma-3-12b-it-quantized-W4A16", "repo": "abhishekchohan/gemma-3-12b-it-quantized-W4A16", "filename": "model-00001-of-00002.safetensors", "folder": "checkpoints", "downloads": 190411, "files": ["model-00001-of-00002.safetensors", "model-00002-of-00002.safetensors"]}, {"name": "gemma-2-2b", "repo": "google/gemma-2-2b", "filename": "model-00001-of-00003.safetensors", "folder": "checkpoints", "downloads": 157094, "files": ["model-00001-of-00003.safetensors", "model-00002-of-00003.safetensors", "model-00003-of-00003.safetensors"]}], "huggingface_count": 14, "hint": "Use model 'id' from registry_matches with comfyui_download_model(model_ids=[...]). For HuggingFace results, use comfyui_download_model(models=[{repo, filename, folder}])."}}

data: {"type": "continuing", "tool_calls_so_far": 49}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_download"}

data: {"type": "token", "text": "_model"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "model"}

data: {"type": "token", "text": "_ids"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " [\""}

data: {"type": "token", "text": "ltx"}

data: {"type": "token", "text": "2"}

data: {"type": "token", "text": "_text"}

data: {"type": "token", "text": "_encoder"}

data: {"type": "token", "text": "\"]"}

data: {"type": "token", "text": "}}"}

data: {"type": "tool_executing", "tool": "comfyui_download_model", "elapsed": 0.0}

data: {"type": "tool_executing", "tool": "comfyui_download_model", "elapsed": 2.9}

data: {"type": "tool_call", "tool": "comfyui_download_model", "tool_number": 50, "arguments": {"model_ids": ["ltx2_text_encoder"]}, "result": {"success": true, "job_id": "eff249d5", "message": "Download started for 1 model(s). Use comfyui_job_status with job_id 'eff249d5' to track progress."}}

data: {"type": "followup_start"}

data: {"type": "token", "text": "{\""}

data: {"type": "token", "text": "tool"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "com"}

data: {"type": "token", "text": "fy"}

data: {"type": "token", "text": "ui"}

data: {"type": "token", "text": "_"}

data: {"type": "token", "text": "await"}

data: {"type": "token", "text": "_job"}

data: {"type": "token", "text": "\","}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "arguments"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " {\""}

data: {"type": "token", "text": "job"}

data: {"type": "token", "text": "_id"}

data: {"type": "token", "text": "\":"}

data: {"type": "token", "text": " \""}

data: {"type": "token", "text": "eff"}

data: {"type": "token", "text": "249"}

data: {"type": "token", "text": "d"}

data: {"type": "token", "text": "5"}

data: {"type": "token", "text": "\"}}"}

data: {"type": "done", "tool_calls_total": 50}

